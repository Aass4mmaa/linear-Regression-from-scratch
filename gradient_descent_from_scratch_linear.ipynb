{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77053a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ab49f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.2 , 0.23, 1.  , 0.4 ],\n",
       "       [1.  , 0.25, 0.56, 0.3 , 0.13],\n",
       "       [1.  , 0.16, 0.18, 0.16, 0.76]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([[0.2, 0.23, 1, 0.4], [0.25, 0.56, 0.3, 0.13], [0.16, 0.18, 0.16, 0.76]]) # try adding more\n",
    "y_train = np.array([460, 232, 178]) # \n",
    "#adding a column for the intercept\n",
    "X_train=np.c_[np.ones(X_train.shape[0]),X_train]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41feeb28",
   "metadata": {},
   "source": [
    "###  calculer les valeurs prédit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b311e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_y(x,w):\n",
    "    \n",
    "    y_pre=x@w\n",
    "\n",
    "    return y_pre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01c06c",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3b0f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(x,y, bw):\n",
    "    \n",
    "    cost =0\n",
    "    m=x.shape[0]\n",
    "\n",
    "    f_wb = outcome_y(x,bw)\n",
    "    ma_in=((f_wb-y_train)**2)\n",
    "    cost=sum(ma_in)/(2*m)\n",
    "    # make the average\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184327fb",
   "metadata": {},
   "source": [
    "### calculer le gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d2a999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w):\n",
    "    \n",
    "    m=X.shape[0]\n",
    "    y_pr=outcome_y(X,w)\n",
    "    dj_b_w=[] \n",
    "    d=(y_pr-y).sum()/m\n",
    "    dj_b_w.append(d)\n",
    "    X=X[::,1:5]\n",
    "    d=X.T@(y_pr-y)/m\n",
    "    dj_b_w.append(d)\n",
    "                               \n",
    "    \n",
    "        \n",
    "    return dj_b_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fd5a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y,bw_in, alpha, num_iters): \n",
    "    # An array to store cost J and w's at each iteration\n",
    "    J_history = []\n",
    "    n=X.shape[1]\n",
    "    #make a copy of w and to avoid modifying global w within function\n",
    "    w = bw_in[1:n]  \n",
    "    b = bw_in[0]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        # compute the gradient\n",
    "        w=np.insert(w,0,b)\n",
    "\n",
    "        dj_b_dw = compute_gradient(X, y, w)\n",
    "        w = w[1:n]  \n",
    "        b = w[0]\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        b= b- alpha*dj_b_dw[0]\n",
    "        w = w- alpha*dj_b_dw[1]\n",
    "        J_history.append(w)\n",
    "        J_history.append(dj_b_dw)\n",
    "        # Save cost J at each iteration\n",
    "\n",
    "                      \n",
    "        \n",
    "        \n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b838b3e",
   "metadata": {},
   "source": [
    "### Regression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "484d90b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.2 ],\n",
       "       [1.  , 0.25],\n",
       "       [1.  , 0.16]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a column for the intercept\n",
    "x_vec=np.c_[np.ones(X_train.shape[0]),X_train[::,1]]\n",
    "x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ed2c21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_wb shape (3,), prediction: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "bw_init = np.zeros(2)\n",
    "\n",
    "\n",
    "f_wb = outcome_y(x_vec,bw_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "033807f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49518.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_function(x_vec,y_train, bw_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9303580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b at initial w,b: -290.0\n",
      "w at initial w,b: [-59.49333333]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_d=compute_gradient(x_vec,y_train, bw_init) \n",
    "print(f'b at initial w,b:', tmp_dj_d[0])\n",
    "print(f'w at initial w,b:',  tmp_dj_d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82061dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6171556052156785\n",
      "[0.59416308]\n"
     ]
    }
   ],
   "source": [
    "iterations = 100# try ,1000\n",
    "alpha = 0.0001 #try / 0.00001 / 0.00000001\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(x_vec,y_train,bw_init, alpha, iterations)\n",
    "\n",
    "print(b_final)\n",
    "print(w_final)\n",
    "#m,_ = X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b4372",
   "metadata": {},
   "source": [
    "### Regression multi-linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "109dff4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.2 , 0.23, 1.  , 0.4 ],\n",
       "       [1.  , 0.25, 0.56, 0.3 , 0.13],\n",
       "       [1.  , 0.16, 0.18, 0.16, 0.76]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a column for the intercept\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "819fa8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_wb shape (3,), prediction: [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "bw_init = np.zeros(5)\n",
    "\n",
    "\n",
    "f_wb = outcome_y(X_train,bw_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05f8af6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49518.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_function(X_train,y_train, bw_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4459ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b at initial w,b: -290.0\n",
      "w at initial w,b: [ -59.49333333  -89.25333333 -186.02666667 -116.48      ]\n"
     ]
    }
   ],
   "source": [
    "#Compute and display gradient \n",
    "tmp_dj_d=compute_gradient(X_train,y_train, bw_init) \n",
    "print(f'b at initial w,b:', tmp_dj_d[0])\n",
    "print(f'w at initial w,b:',  tmp_dj_d[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8768bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153393708955793\n",
      "[0.59248015 0.88882947 1.85331577 1.15960512]\n"
     ]
    }
   ],
   "source": [
    "iterations = 100# try ,1000\n",
    "alpha = 0.0001 #try / 0.00001 / 0.00000001\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X_train,y_train,bw_init, alpha, iterations)\n",
    "\n",
    "print(b_final)\n",
    "print(w_final)\n",
    "#m,_ = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f79b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
